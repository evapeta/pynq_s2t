{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a24015-0e27-4063-b0cd-a6916e41e2ee",
   "metadata": {},
   "source": [
    "# Rev.ai Microphone Stream output\n",
    "Writing the output directly to the webcam then writing to the HDMI output.\n",
    "Note, for testing purposes alone so haven't included a script for recorded output text.\n",
    "## Importing Relavent Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78361f08-253a-48dd-a269-12e84ccfab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import numpy as np\n",
    "import time\n",
    "import ipywidgets as ipw\n",
    "from matplotlib import pyplot as plt\n",
    "import queue\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from rev_ai.models import MediaConfig\n",
    "from rev_ai.streamingclient import RevAiStreamingClient\n",
    "from PPFunctions_Live import *\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c038524-2365-4e71-9e70-e8e745c0b120",
   "metadata": {},
   "source": [
    "## Hardware Constraints for Board:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce9b54d0-6f5a-4b8f-84e9-3248f5b223f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.lib.video import *\n",
    "base = BaseOverlay(\"base.bit\")\n",
    "\n",
    "pAudio = base.audio\n",
    "pAudio.set_volume(20)\n",
    "pAudio.select_microphone() # using AUX cable connected to Headphones as microphone input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff19374-2310-487a-b338-3b7f4158ae44",
   "metadata": {},
   "source": [
    "# Applying OpenCV filters on Webcam input\n",
    "### 1. Initialize HDMI I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d09c97-e641-4e11-8675-76fe99c7449b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0xa2068550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# monitor configuration: 640*480 @ 60Hz\n",
    "Mode = VideoMode(640,480,24)\n",
    "hdmi_out = base.video.hdmi_out\n",
    "hdmi_out.configure(Mode,PIXEL_BGR)\n",
    "hdmi_out.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2347da-6b03-451a-9a8a-25aee8389adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera (input) configuration\n",
    "frame_in_w = 640\n",
    "frame_in_h = 480"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1bfdbb-21f1-4b13-b6f7-f6bc2237bd25",
   "metadata": {},
   "source": [
    "### Step 2: Initialize camera from OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50c029-9a40-4f9d-a64b-dfab48eb7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "videoIn = cv2.VideoCapture(0)\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_WIDTH, frame_in_w);\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_in_h);\n",
    "print(\"capture device is open: \" + str(videoIn.isOpened()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e99ca9b-5f94-4b86-8c85-29476639073e",
   "metadata": {},
   "source": [
    "### Function to Display Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bebc11-475f-437b-8f29-5365e802b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_output(sub, videoIn):\n",
    "    ret, frame_vga = videoIn.read()\n",
    "\n",
    "    if (ret):\n",
    "        outframe = hdmi_out.newframe()\n",
    "        outframe[:] = frame_vga\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 0.8\n",
    "\n",
    "        # area of interest, where subtitles are placed:\n",
    "        tr = int(frame_in_w - 10), int(frame_in_h - 34)\n",
    "        bl = 10, int(frame_in_h - 3)\n",
    "\n",
    "        x = int(10)\n",
    "        y = int(frame_in_h - 10)\n",
    "\n",
    "        img = cv2.rectangle(outframe, tr, bl, (0, 0, 0), -1)\n",
    "        image = cv2.putText(img, sub, (x, y), font, font_scale, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        hdmi_out.writeframe(img)\n",
    "    else:\n",
    "        raise RuntimeError(\"Error while reading from camera.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac834a1c-1fc5-449a-9a1b-8f43dd1f85fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoThreading():\n",
    "    def __init__(self, start=True):\n",
    "        self.stopping = True\n",
    "        self.sub = \"\"\n",
    "        \n",
    "    def _do(self):\n",
    "        while not self.stopping:\n",
    "            video_output(self.sub, videoIn)\n",
    "            sleep(0.125)\n",
    "        \n",
    "    def start(self):\n",
    "        if self.stopping:           \n",
    "            self.stopping = False\n",
    "            thread = threading.Thread(target=self._do)\n",
    "            thread.start()\n",
    "        \n",
    "    def stop(self):\n",
    "        self.stopping = True\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3bf690-b643-4d92-bbe9-bd970ffb3011",
   "metadata": {},
   "source": [
    "# Defining Microphone Stream\n",
    "Threaded class used to process audio into subtitles in real-time. Code based upon example from Strath-SDR RFSoC QPSK and rev.ai sample python code.\n",
    "## Audio Thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa367745-97ea-4c24-aae8-18cac05ad112",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioThreading():\n",
    "    def __init__(self, pynq_audio, record_time, chunk, start=True, src=0):\n",
    "        \"\"\"\n",
    "        Create new dma-based data timer.\n",
    "        callback: function to call with data chunk\n",
    "        gen: function to call to return data chunk\n",
    "             (usually a dma channel's transfer function)\n",
    "        \"\"\"\n",
    "        self.stopping = not start\n",
    "        self.record_time = record_time\n",
    "        self._buffer = queue.Queue()\n",
    "        self._pynq_audio = pynq_audio\n",
    "        self.chunk = chunk\n",
    "        self.closed = True\n",
    "        \n",
    "        self.stopped = False\n",
    "\n",
    "    def _do(self):\n",
    "        \"\"\"\n",
    "        Generate new data and restart timer thread.\n",
    "        Should never be run directly. use `start()` instead.\n",
    "        \"\"\"\n",
    "        while not self.stopping:\n",
    "            self._pynq_audio.record(self.record_time)\n",
    "            self._buffer.put(self._pynq_audio.buffer << 8)\n",
    "\n",
    "    def __enter__(self):\n",
    "        \n",
    "        self._audio_interface = self._pynq_audio\n",
    "        \n",
    "        \"\"\" Start the data generator thread. \"\"\"\n",
    "        if not self.stopping:           \n",
    "            self.stopping = False\n",
    "            thread = threading.Thread(target=self._do)\n",
    "            thread.start()\n",
    "            \n",
    "        self.closed = False\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        \"\"\"\n",
    "        Stop a running data generator thread.\n",
    "        Does not need a lock, since the spawned timer thread will only read `self.stopping`.\n",
    "        \"\"\"\n",
    "        self.stopped = True\n",
    "        self.closed = True\n",
    "        self._buffer.put(None)\n",
    "    \n",
    "    # Rev.ai Code example for microphone stream:\n",
    "    def generator(self):\n",
    "        while not self.stopping:\n",
    "            \"\"\"\n",
    "            Use a blocking get() to ensure there's at least one chunk of\n",
    "            data, and stop iteration if the chunk is None => stop on pause!\n",
    "            \"\"\"\n",
    "            chunk = self._buffer.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buffer.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "            yield b''.join(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d26d3a-4f3e-41d9-9c99-475200f653f4",
   "metadata": {},
   "source": [
    "## Personal Access Token for Rev.ai:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ad0a8f-dd31-49a7-9e2b-37cec1eabd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = \"020xN8wEvpFJ57K5xz4CjnhKVkC0kDJO74fKvx58chPRJQHUChMfrQyTWWooMnfO5H5kyGiVdHJHSroppSQFIU9g69v2E\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6586a8a-0015-484f-b266-65aad2d6c032",
   "metadata": {},
   "source": [
    "## Routing Audio Through Logic Fabric:\n",
    "Sampling rate of Audio Codec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14746730-1a3c-45c7-b0be-11ae5c291bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 48 * 1000 # Technically, codec is 96 kHz, however two channels will be used\n",
    "chunk = int(rate/20000) # Approx 4s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82071ef3-8eb6-4b9c-b323-887edfd0e112",
   "metadata": {},
   "source": [
    "## Raw Microphone Input to Create Media Config:\n",
    "96 kHz interleaved, signed 32-bit, dual channel audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb13def5-1ed1-46aa-b74c-505da8f869c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_mc = MediaConfig('audio/x-raw', 'interleaved', rate, 'S32LE', 2) \n",
    "streamclient = RevAiStreamingClient(access_token, example_mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2b9e6b-e546-4570-a2c7-0d0957dad45c",
   "metadata": {},
   "source": [
    "## Starting Video Thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458db7c9-dcd9-4d8b-95e0-08037adaedd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_thread = VideoThreading()\n",
    "video_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a626b041-774e-4534-8d22-1100f1aa9661",
   "metadata": {},
   "source": [
    "## Opens microphone input, input will stop after a keyboard interrupt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b05b0d-472a-4933-b157-eb8014479ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_prev = ''\n",
    "\n",
    "with AudioThreading(pAudio, 1, chunk) as stream:\n",
    "\n",
    "    try:\n",
    "        ## Starts the server connection and thread sending microphone audio\n",
    "        print(\"new chunk!\")\n",
    "        response_gen = streamclient.start(stream.generator())\n",
    "        ## Iterates through responses and prints them\n",
    "        for response in response_gen:\n",
    "            sub = real_t(response)\n",
    "            if sub != sub_prev:\n",
    "                sub_prev = sub\n",
    "                video_thread.sub = sub_prev\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        stream.stopping = True\n",
    "        ## Ends the WebSocket connection.\n",
    "        streamclient.end()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b9be1a-1726-4eb9-ab9f-b169001a8448",
   "metadata": {},
   "source": [
    "## Closing Webcam Connection and HDMI Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af886492-63e0-436e-86b4-9891fc4f5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "videoIn.release()\n",
    "hdmi_out.stop()\n",
    "del hdmi_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b483d-db12-43c6-a234-0e7af94cb493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
