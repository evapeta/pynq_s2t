{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08890475-6c4d-418f-87af-217f3e3e8dbe",
   "metadata": {},
   "source": [
    "# Live Time Subtitling Using Microphone Input\n",
    "Using the google speech-to-text API, hence, this is technically required to be online\n",
    "## Defining the hardware constraints of the PYNQ-Z2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec6f7139-30c0-4ddc-b1cc-404047e9c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq.overlays.base import BaseOverlay\n",
    "base = BaseOverlay(\"base.bit\")\n",
    "pAudio = base.audio\n",
    "Microphone = pAudio.select_microphone() # using AUX cable connected to Headphones as microphone input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bc1d0f-96bf-43b0-8841-de1e2df641c3",
   "metadata": {},
   "source": [
    "## Function to accept microphone as input for speech-to-text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48e5d204-678a-4202-8f35-6d349db37287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(duration):\n",
    "    import speech_recognition as sr\n",
    "    dur = int(duration)\n",
    "    r = sr.Recognizer()\n",
    "    print(\"Say something!\")\n",
    "\n",
    "    with Microphone as source:\n",
    "        # audio = r.listen(source) # Automatically stops when a pause is in the speech\n",
    "        audio = r.record(source, duration = dur) # Stops after 3s\n",
    "        said  = \"\"\n",
    "\n",
    "        try:\n",
    "            said = r.recognize_google(audio) # using google API to understand audio\n",
    "            print(\"What we understand you said was: \")\n",
    "            print(said)\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Google Speech Recognition could not understand audio\")\n",
    "        except sr.RequestError as e:\n",
    "            print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "    return said"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1380694-6967-44e7-808f-0edf62d65b21",
   "metadata": {},
   "source": [
    "## Calling Function to Collect Microphone Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "688bd5a2-18c9-496b-ac1a-d3705e0eae08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "__enter__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1740dddab21d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspeech\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sampling audio for 3 seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-9e8b7011d870>\u001b[0m in \u001b[0;36mget_audio\u001b[0;34m(duration)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Say something!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mMicrophone\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m# audio = r.listen(source) # Automatically stops when a pause is in the speech\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdur\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Stops after 3s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: __enter__"
     ]
    }
   ],
   "source": [
    "speech = get_audio(3) # sampling audio for 3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f30328c-7075-4191-8a4a-10c9bb2f1f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
